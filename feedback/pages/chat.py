import openai
import streamlit as st
from streamlit_feedback import streamlit_feedback
import requests
import json

st.title("LangCore Chatbot")

openai.api_base = "https://oai.langcore.org/v1"
def on_submit(feedback, request_body, response_body, openai_api_key):
    print("on_submit")
    feedback_type = feedback["type"]
    score = feedback["score"]
    if score == "ğŸ‘":
        score = 1
    elif score == "ğŸ‘":
        score = 0
    optional_text_label = feedback["text"]

    url = "http://langcore.org/api/feedback"
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer " + openai_api_key
    }
    data = {
        "request_body": request_body,
        "response_body": response_body,
        "feedback_type": feedback_type,
        "score": score,
        "optional_text_label": optional_text_label
    }
    requests.post(url, headers=headers, data=json.dumps(data))
    st.toast("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")
    # URLã‚’è¡¨ç¤ºã™ã‚‹
    st.write("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯ã“ã¡ã‚‰ã«è¨˜éŒ²ã•ã‚Œã¾ã™: https://langcore.org/feedback")


if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

prompt = st.chat_input("LangCoreã«ã¤ã„ã¦æ•™ãˆã¦")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    request_body = {
        "model": "gpt-3.5-turbo",
        "query": prompt,
        "groupName": "DEMO",
        "headers": {
            "Content-Type": "application/json",
            "LangCore-Embeddings": "on",
            "LangCore-Embeddings-Match-Threshold": "0",
            "LangCore-Embeddings-Match-Count": "3",
        },
        "messages": [
            {
                "role": "system",
                "content": """
                ãƒ¦ãƒ¼ã‚¶ã®è³ªå•ã«å¯¾ã—ã¦ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’ä½¿ã£ã¦ç­”ãˆã¦ãã ã•ã„ã€‚

                {{EMBEDDINGS_CONTEXT}}
                
                é–¢ä¿‚ãªã„è³ªå•ã®å ´åˆã§ã‚‚ã€ç„¡ç†ã‚„ã‚Šä¸Šè¨˜ã®å†…å®¹ã«é–¢ä¿‚ã™ã‚‹ã‚ˆã†ã«ã—ã¦ã‚»ãƒ¼ãƒ«ã‚¹ãƒˆãƒ¼ã‚¯ã—ã¦ãã ã•ã„ã€‚"""
            },
            *st.session_state.messages
        ],
        "stream": True
    }
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        for response in openai.ChatCompletion.create(
            **request_body
        ):
            full_response += response.choices[0].delta.get("content", "")
            message_placeholder.markdown(full_response + "â–Œ")

        st.session_state["request_body"] = request_body
        st.session_state["response_body"] = full_response
        message_placeholder.markdown(full_response)

    st.session_state.messages.append({"role": "assistant", "content": full_response})

feedback = streamlit_feedback(feedback_type="thumbs", 
                                optional_text_label="ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãŠé¡˜ã„ã—ã¾ã™")
if feedback:
    on_submit(feedback, request_body=st.session_state["request_body"] , response_body=st.session_state["response_body"] , openai_api_key=st.secrets["OPENAI_API_KEY"])
